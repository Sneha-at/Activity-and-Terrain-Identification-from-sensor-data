{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_code_c1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhBGzvpA5879"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJzsbTth6BX8"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob \n",
        "import numpy as np\n",
        "import random\n",
        "import sklearn.metrics\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
        "from keras.layers import LSTM, LSTM, SimpleRNN, GRU, Bidirectional, Conv2D, Reshape\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from statsmodels import robust\n",
        "from scipy import  stats\n",
        "from scipy.stats import entropy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02DGh8FJ6Ill"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djeqmB0p6bF1"
      },
      "source": [
        "## Read the Data Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZVEQZF56S6M"
      },
      "source": [
        "def upsample_label(temp_x, temp_y):\n",
        "    y_time_list = temp_y['time'].values\n",
        "    y_label = temp_y['label'].values\n",
        "    jdx = 0\n",
        "    label_list = []\n",
        "    for index,row in temp_x.iterrows():\n",
        "        try:\n",
        "            if row['time'] > y_time_list[jdx]:\n",
        "                jdx+=1\n",
        "            label_list.append(y_label[jdx])\n",
        "        except:\n",
        "            label_list.append(0)\n",
        "    return label_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiB65JoT65Ha"
      },
      "source": [
        "dir_path = 'drive/MyDrive/TrainingData/'\n",
        "column_list = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z','subject', 'time', 'label']\n",
        "df_data = pd.DataFrame([], columns = column_list)\n",
        "\n",
        "for idx in glob.glob(dir_path + '*.csv'):\n",
        "    df_type = idx.split('.')[0].split('__')[1]\n",
        "    if df_type == 'x':\n",
        "        subject_name = idx.split('.')[0].split('__')[0].split('/')[-1]\n",
        "        x_path = idx.split('.')[0].split('__')[0] + '__' + df_type + '.csv'\n",
        "        x_time_path = idx.split('.')[0].split('__')[0] + '__' + 'x_time' + '.csv'\n",
        "        y_path = idx.split('.')[0].split('__')[0] + '__' + 'y' + '.csv'\n",
        "        y_time_path = idx.split('.')[0].split('__')[0] + '__' + 'y_time' + '.csv'\n",
        "        \n",
        "        df_x = pd.read_csv(x_path)\n",
        "        \n",
        "        sub_name = [subject_name]*df_x.shape[0]\n",
        "        df_x['subject'] = sub_name\n",
        "        \n",
        "        df_x_time = pd.read_csv(x_time_path)\n",
        "        df_x['time'] = df_x_time\n",
        "        \n",
        "        df_y = pd.read_csv(y_path)\n",
        "        sub_name = [subject_name]*df_y.shape[0]\n",
        "        df_y['subject'] = sub_name\n",
        "        \n",
        "        df_y_time = pd.read_csv(y_time_path)\n",
        "        df_y['time'] = df_y_time\n",
        "        df_y.columns = ['label', 'subject', 'time']\n",
        "        label_list = upsample_label(df_x, df_y)\n",
        "        df_x['label'] = label_list\n",
        "        df_x.columns = column_list\n",
        "        df_data = pd.concat([df_data, df_x], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giYC1rm6XPjv"
      },
      "source": [
        "## Scaling Input Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMXahQOk7E3e"
      },
      "source": [
        "scale_columns = df_data.columns[:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D81rJGtgXW9Z"
      },
      "source": [
        "scaler = RobustScaler()\n",
        "\n",
        "scaler = scaler.fit(df_data[scale_columns])\n",
        "\n",
        "df_data.loc[:, scale_columns] = scaler.transform(\n",
        "  df_data[scale_columns].to_numpy()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpOTzbX4Xgti"
      },
      "source": [
        "def create_windows(X, y, time_steps=1, step=1):\n",
        "    Xs, ys = [], []\n",
        "      \n",
        "    for i in range(0, len(X) - time_steps, step):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        labels = y.iloc[i: i + time_steps]\n",
        "        Xs.append(v)\n",
        "        ys.append(stats.mode(labels)[0][0])\n",
        "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-d1TcX2XlF7"
      },
      "source": [
        "def create_test_windows(X, time_steps=1, step=1):\n",
        "  Xs = []\n",
        "  for i in range(0, len(X) - time_steps, step):\n",
        "    v = X.iloc[i:(i + time_steps)].values\n",
        "    Xs.append(v)\n",
        "  return np.array(Xs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "392ZwyGvXomf"
      },
      "source": [
        "TIME_STEPS = 40  # Window Size\n",
        "STEP = 1\n",
        "\n",
        "X_data, y_data = create_windows(X=df_data[scale_columns], y=df_data.label, time_steps=TIME_STEPS,step=STEP)\n",
        "\n",
        "X_data = np.expand_dims(X_data, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZdoDo8Y_uR"
      },
      "source": [
        "## Performing Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LylSDdoYX3sw"
      },
      "source": [
        "df_label = pd.DataFrame(y_data, columns=['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geKdufX1d3FR"
      },
      "source": [
        "df_label['index_'] = df_label.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtttPaJ8d4ps",
        "outputId": "c66461b8-47ed-4e46-f3f1-076700e552e1"
      },
      "source": [
        "## Library for performing undersampling \n",
        "rus = RandomUnderSampler(sampling_strategy='not minority', random_state=1)\n",
        "df_balanced, balanced_labels = rus.fit_resample(df_label, df_label['label'])\n",
        "df_balanced = pd.DataFrame(df_balanced, columns=['label', 'index_'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViKPdhyeAf8"
      },
      "source": [
        "X_data = X_data[df_balanced['index_'].values]\n",
        "y_data = y_data[df_balanced['index_'].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9u1jvZpeDWP"
      },
      "source": [
        "val_size = 0.1  # validation data size\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=val_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WTcRts_eIWK"
      },
      "source": [
        "## Converting label to OneHot Encoding\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "enc = enc.fit(y_train)\n",
        "y_train = enc.transform(y_train)\n",
        "y_val = enc.transform(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fgNMQ6LhEkF"
      },
      "source": [
        "## Model Defination "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gopzz1w9hCYh"
      },
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "output_dim = 4\n",
        "lr = 0.001\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(128, kernel_size=(5, 1), input_shape=input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(5, 1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(5, 1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(5, 1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Reshape((24, 6*128)))\n",
        "\n",
        "layer = LSTM(128, activation=\"tanh\", return_sequences=True)\n",
        "model.add(layer)\n",
        "#model.add(LSTM(128, activation=\"tanh\", return_sequences=True))\n",
        "\n",
        "model.add(Dropout(0.5, seed=0))\n",
        "model.add(LSTM(256, activation=\"tanh\"))\n",
        "t\n",
        "model.add(Dropout(0.5, seed=1))\n",
        "model.add(Dense(output_dim))\n",
        "\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam'\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\", optimizer= opt, metrics=[\"acc\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p67U-iewhXX5"
      },
      "source": [
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_val = np.asarray(X_val).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTWJHjAhiNo"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUtR0pqPhpGG"
      },
      "source": [
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data = (X_val, y_val),\n",
        "    epochs=1,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxvgHv4whvoD"
      },
      "source": [
        "## Evaluation result on val set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcQXnw6NhzV6"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "y_val = np.argmax(y_val, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkrWn9XniAXv"
      },
      "source": [
        "acc_score = sklearn.metrics.accuracy_score(y_val, y_pred)\n",
        "f1_score = sklearn.metrics.f1_score(y_val, y_pred, average='macro')\n",
        "recall = sklearn.metrics.recall_score(y_val, y_pred, average='macro')\n",
        "precision = sklearn.metrics.precision_score(y_val, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWNHiByliFZO",
        "outputId": "a5b1bfed-ac8a-4424-eb75-736af7fb32a4"
      },
      "source": [
        "## Results on validation set \n",
        "print(f'accuracy --> {acc_score}', f'f1_score --> {f1_score}', f'recall --> {recall}', f'precision --> {precision}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy --> 0.5877966718195872 f1_score --> 0.5755326159081701 recall --> 0.5863732187880732 precision --> 0.6050176559737992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvFrFagjI-8"
      },
      "source": [
        "## Inference on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89LnBN2RjT1Q"
      },
      "source": [
        "from scipy.stats import mode\n",
        "dir_path = 'drive/MyDrive/TestData/'\n",
        "column_list = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z','subject', 'time']\n",
        "df_test_data = pd.DataFrame([], columns = column_list)\n",
        "\n",
        "## Reading prediction file \n",
        "for idx in glob.glob(dir_path + '*.csv'):\n",
        "    df_type = idx.split('.')[0].split('__')[1]\n",
        "\n",
        "    if df_type == 'x':\n",
        "      subject_name = idx.split('.')[0].split('__')[0].split('/')[-1]\n",
        "      x_path = idx.split('.')[0].split('__')[0] + '__' + df_type + '.csv'\n",
        "      x_time_path = idx.split('.')[0].split('__')[0] + '__' + 'x_time' + '.csv'\n",
        "      y_time_path = idx.split('.')[0].split('__')[0] + '__' + 'y_time' + '.csv'\n",
        "      df_x = pd.read_csv(x_path, names=column_list[:6])\n",
        "      df_x = df_x.iloc[1:]\n",
        "      df_x.loc[:, scale_columns] = scaler.transform(\n",
        "              df_x[scale_columns].to_numpy()\n",
        "      )\n",
        "\n",
        "      ## Converting windows for test data \n",
        "      sampled_test = create_test_windows(df_x[scale_columns],TIME_STEPS, STEP )\n",
        "      print(len(sampled_test))\n",
        "\n",
        "      ## Making inference on test data \n",
        "      sampled_test = np.expand_dims(sampled_test, -1)\n",
        "      pred_test = model.predict(sampled_test)\n",
        "      pred_test = np.argmax(pred_test, axis=1)\n",
        "      pred_test = list(pred_test)\n",
        "      pred_test = np.asarray(pred_test)\n",
        "      pred_test = np.concatenate([pred_test, np.asarray([pred_test[-1]]*120)])\n",
        "      pred_test = pd.DataFrame(pred_test, columns=['label'])\n",
        "\n",
        "      ## Sampling the prediction to match the test set sampling frequency. \n",
        "      df_mode = pred_test['label'].rolling(window=4, min_periods=1).apply(lambda x: mode(x)[0])[::4]\n",
        "\n",
        "      ## Saving the test set prediction\n",
        "      y_label = []\n",
        "\n",
        "      y_time = pd.read_csv(y_time_path).shape[0]\n",
        "      print(y_time, len(pred_test), len(y_label))\n",
        "    \n",
        "      pred_df = pd.DataFrame(df_mode.values)\n",
        "      pred_df.to_csv('drive/MyDrive/' + subject_name + '__y_prediction.csv', index=False, columns=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7aPwUi0cP0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}